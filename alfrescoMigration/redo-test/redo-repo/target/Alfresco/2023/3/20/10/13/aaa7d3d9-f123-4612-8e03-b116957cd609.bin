
Summary
Ki Hyun Kim

nlp.with.deep.learning@gmail.com




â€¢ e.g.ï¿½Tabularï¿½Data,ï¿½Image â€¢ e.g.ï¿½Sequentialï¿½Data,ï¿½Time-series

Recurrentï¿½Neuralï¿½Networks

Previousï¿½methods Recurrentï¿½Neuralï¿½Networks

ğ‘¥ ğ‘¦ ğ‘¥! â„!

ğ‘¦



Tensorï¿½Shapes

â€¢ Singleï¿½layerï¿½RNNì—ì„œ hiddenï¿½stateëŠ” ê³§ outputì´ë‹¤.

â€¢ Multi-layeredï¿½RNNì—ì„œ
â€¢ Outputì€ ë§ˆì§€ë§‰ layerì˜ ëª¨ë“  time-stepì˜ hiddenï¿½stateì´ë‹¤.
â€¢ Hiddenï¿½stateëŠ” ë§ˆì§€ë§‰ time-stepì˜ ëª¨ë“  layerì˜ hiddenï¿½stateì´ë‹¤.

â€¢ Bi-directionalï¿½RNNì—ì„œ
â€¢ Outputì€ hiddenï¿½stateê°€ 2ë°°ê°€ëœë‹¤.
â€¢ Hiddenï¿½stateëŠ” layerì˜ ê°¯ìˆ˜ê°€ 2ë°°ê°€ëœë‹¤.



BPTT

â€¢ ì—¬ëŸ¬ê²½ë¡œë¡œ feed-forwardï¿½ë  ê²½ìš°, back-propagation í•  ë•Œ,
ìµœì¢… gradient ê°’ì€ê°ê²½ë¡œì˜ gradientë“¤ì˜ì´í•©ì´ëœë‹¤.

â€¢ RNNì˜ê²½ìš°ì—ë„ê° time-stepì— ë”°ë¼ feed-forwardë˜ë¯€ë¡œ,
ê° ê²½ë¡œë¡œë¶€í„°ì „ë‹¬ë˜ì–´ì˜¨ gradientë“¤ì´ë”í•´ì§„ë‹¤.

â€¢ ë”°ë¼ì„œ time-stepì˜ ê°¯ìˆ˜ë§Œí¼ë ˆì´ì–´ê°€ê¹Šì–´ì§„ê²ƒê³¼ë§ˆì°¬ê°€ì§€ì´ë¯€ë¡œ,
tanhë¥¼ í™œì„±í•¨ìˆ˜ë¡œì‚¬ìš©í•˜ëŠ” RNNì€ gradientï¿½vanishingì´ ë°œìƒí•œë‹¤.



Applications

!" !# !$ !%
&'

!"
&'" &'# &'$ &'%

&'" &'# &'$ !" !# !$
&'" &'# &'$

&'" &'#&'(

Many to One

One to Many

Many to Many

!"
&'" &'# &'$ &'%

!# !$ !%

NLG, Machine Translation

POS Tagging, MRC

Text Classification

Architecture ApplicationsType


