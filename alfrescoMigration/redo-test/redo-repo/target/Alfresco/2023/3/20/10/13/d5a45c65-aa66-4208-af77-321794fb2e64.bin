
Transferï¿½Learning
usingï¿½Backbone

Ki Hyun Kim

nlp.with.deep.learning@gmail.com




Featureï¿½Extractionï¿½inï¿½eachï¿½Layer

â€¢ ê° conv.ï¿½layerëŠ” ìœ„ì¹˜ì—ë”°ë¼,
low-levelï¿½ë˜ëŠ” high-levelï¿½featureë¥¼ ì¶”ì¶œí•˜ë„ë¡í•™ìŠµë¨.

â€¢ ë”°ë¼ì„œ ImageNetì˜ ë°ì´í„°14,197,122ì¥ë¥¼í†µí•´í•™ìŠµëœë„¤íŠ¸ì›Œí¬(e.g.ï¿½VGGNet)ëŠ”
í•´ë‹¹ taskë¥¼ ìˆ˜í–‰í•˜ê¸°ìœ„í•œ featureï¿½extraction ëŠ¥ë ¥ì´ìˆì„ê²ƒ

CNNï¿½Block

(ğ‘ = 1, ğ¶ = 1,28,28) (32,14,14) (64,7,7) (128,4,4) (1, â„ = 50) (1,10)
CNNï¿½Block CNNï¿½Block CNNï¿½Block

(256,2,2)

so
ftm

ax

F
C
ï¿½Laye

r

F
C
ï¿½Laye

r

(512,1,1)

CNNï¿½Block



Motivations

â€¢ ë°ì´í„°ê°€ë‹¤ë¥´ë”ë¼ë„ì´ë¯¸ì§€ë¥¼í™œìš©í•œ taskì—ì„œëŠ”ê³µí†µëœ featureë“¤ì´ì¡´ì¬í• ê²ƒ

CelebA-HQï¿½DatasetFlowerï¿½imageï¿½Dataset



Transferï¿½Learningì´ë€?

â€¢ Transferï¿½learning isï¿½aï¿½researchï¿½problemï¿½in machineï¿½learning
thatï¿½focusesï¿½onï¿½storingï¿½knowledgeï¿½gainedï¿½whileï¿½solvingï¿½oneï¿½problem
andï¿½applyingï¿½itï¿½toï¿½aï¿½differentï¿½butï¿½relatedï¿½problem.

Bigï¿½Dataset
e.g.ï¿½ImageNet

Targetï¿½
Dataset

Pretraining

Fine-tuning

Loadï¿½weights

ì¶œì²˜: ìœ„í‚¤í”¼ë””ì•„(https://en.wikipedia.org/wiki/Transfer_learning)




Howï¿½to

1) Setï¿½seedï¿½weightsï¿½andï¿½trainï¿½asï¿½normal

2) Fixï¿½loadedï¿½weightsï¿½andï¿½trainï¿½unloadedï¿½parts

3) Trainï¿½withï¿½differentï¿½learningï¿½rateï¿½onï¿½eachï¿½part

ğœƒ = ğœ™,ğœ“ğ‘¥ "ğ‘¦
ğœ™ ğœ“

#ğœ“ "ğ‘¦ğ‘¥Bigï¿½Dataset
e.g.ï¿½ImageNet

Targetï¿½
Dataset



Summary

â€¢ í°ë°ì´í„°ì…‹ì„í†µí•´ë¯¸ë¦¬í›ˆë ¨í•œë„¤íŠ¸ì›Œí¬ë¥¼ë‚˜ì˜ë¬¸ì œì—ì¬í•™ìŠµì‹œí‚¤ì.
â€¢ ì¸í„°ë„·ì—ê³µê°œë˜ì–´ìˆëŠ”ë§ì€ë„¤íŠ¸ì›Œí¬ë“¤

â€¢ Computerï¿½Visionï¿½ì´ì™¸ì˜ë„ë©”ì¸(íŠ¹íˆ NLP)ì—ì„œë„í°ì¸ê¸°ë¥¼ëŒê³ ìˆìŒ.
â€¢ e.g.ï¿½BERT,ï¿½GPT


