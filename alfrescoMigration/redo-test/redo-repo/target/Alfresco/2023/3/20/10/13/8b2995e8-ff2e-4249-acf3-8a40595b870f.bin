
Autoencoders
Ki Hyun Kim

nlp.with.deep.learning@gmail.com




Overview

• 인코더(encoder)와 디코더(decoder)를 통해압축과해제를실행
• 인코더는입력(𝑥)의 정보를최대한보존하도록손실압축을수행
• 디코더는중간결과물(𝑧)의 정보를입력(𝑥)과 같아지도록압축해제(복원)를 수행

• 복원을성공적으로하기위해,
오토인코더(autoencoder)는 특징(feature)을 추출하는방법을자동으로학습

𝑧𝑥 #𝑥Encoder Decoder



Encoder

• 복원에필요한정보를중심으로손실압축을수행
• 필요없는정보(뻔한특징)는 버릴수도있음
(e.g.�일반적인사람의얼굴을학습할때: 사람의얼굴에서눈은 2개다)

𝑧𝑥 #𝑥Encoder Decoder
Bottleneck



Bottleneck

• 입력(𝑥)에 비해작은차원으로구성
• 따라서정보의선택과압축이발생, 차원에따라압축의정도를결정함

• 집에불이나서탈출할때, 무엇을들고나갈것인가?

• 그러므로 𝑧는입력(𝑥)에 대한 feature vector라고할수있다.
• 압축의효율이높아야하므로, 입력에비해 dense�vector일 것.

𝑧𝑥 #𝑥Encoder Decoder
Bottleneck



Decoder

• 압축된중간결과물(𝑧)을 바탕으로최대한입력(𝑥)과 비슷하게복원: #𝑥
• 보통MSELoss 를 통해최적화수행

• 뻔한정보는주어지지않더라도어차피알수있기에복원가능

𝑧𝑥 #𝑥Encoder Decoder
Bottleneck



Summary

• 오토인코더(AE)는 압축과해제를반복하며특징추출을자동으로학습
• 필요한정보와필요없는정보를구분할수있게되는것

• 인코더로부터나온중간결과물(𝑧)은 입력(𝑥)에 대한 feature�vector이다.
• a.k.a Embedding�Vector
• 인코더에통과시키는것은 feature�vector에 대한 embedding�과정이라고볼수있음


