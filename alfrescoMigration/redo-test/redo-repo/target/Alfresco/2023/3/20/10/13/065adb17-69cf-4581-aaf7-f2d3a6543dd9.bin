
Maximum�Likelihood�
Estimation

Ki Hyun Kim

nlp.with.deep.learning@gmail.com




대한민국국민신장의분포를알고싶어요.

1. 밖으로나간다.

2. 지나가는사람을찾는다.

3. 붙잡고키를물어본다.

4. 충분한샘플이모일때까지반복한다.

5. 평균과표준편차를구한다.



좀더멋있게(?)

1. 밖으로나간다.

2. 지나가는사람을찾는다.

3. 붙잡고키를물어본다.

4. 충분한샘플이모일때까지반복한다.

5. 평균과표준편차를구한다.

Ground�Truth�Probability�Density



Gaussian�Example

Samples�from�
Ground�Truth�Probability�Distribution



Gaussian�Example

Approximation�1



Gaussian�Example

Approximation�2



Gaussian�Example

Approximation�3

Line’s�length�=�probability�density



Gaussian�Example

We�found�the�parameters�from�the�approximation�:�𝝁 and�𝝈.

Likelihood 𝜇, 𝜎 =/!"#$ 𝑝 𝑥!; 𝜇, 𝜎
𝐷 = 𝑥! !"#$



Likelihood�Function

• 입력으로주어진확률분포(파라미터)가 데이터를얼마나잘설명하는지
나타내는점수(Likelihood)를 출력하는함수

• 입력: 확률분포를표현하는파라미터
• 출력: 데이터를설명하는정도

• 데이터를잘설명하는지알수있는방법
• 데이터가해당확률분포에서높은확률값을가질것

without�Deep�Learning



Example

• 내기를좋아하는기현이는어느날주사위게임에서돈을많이잃었습니다.
사기당한것을깨달은기현이는복수를위해주사위의트릭을알고싶습니다.
다행히기현이는기억력이좋아서주사위의나온숫자를모두기억하고있습니다.

• 20번 던졌을때, 나온숫자

𝒟 = 5, 6, 4, 6, 5, 2, 6, 1, 5, 3, 1, 6, 4, 2, 5, 6, 2, 1, 4, 5



Example�by�Simple�Solution

• 해당숫자가나온횟수와전체횟수를알면, 확률값을추측할수있다.

• 이에비춰주사위 3이나올확률은?

숫자 횟수

1 3

2 3

3 1

4 3

5 5

6 5

0.15 0.15

0.05

0.15

0.25 0.25

0

0.1

0.2

0.3

1 2 3 4 5 6𝜃 = 𝑤3 = 0.15,𝑤4 = 0.15,𝑤5 = 0.05,𝑤6 = 0.15,𝑤7 = 0.25,𝑤8 = 0.25
𝑃9 (x=3)=0.05



Example�by�Maximum�Likelihood�Estimation

• 목표: 주사위의확률분포를알고싶다.

• 임의의확률분포생성

0.1 0.1 0.1 0.1 0.1

0.5

0

0.2

0.4

0.6

1 2 3 4 5 6

0.5

0.1 0.1 0.1 0.1 0.1
0

0.2

0.4

0.6

1 2 3 4 5 6

𝜃3 𝜃4

ℒ 𝜃% = &!"#&"%'𝑃(! x=𝑥! =.5)×.1)×.1#×.1)×.1*×.1*= 1.25𝑒 − 18
ℒ 𝜃# = &!"#&"%'𝑃(" x=𝑥! =.1)×.1)×.1#×.1)×.1*×.5*= 3.125𝑒 − 17



Example�by�Maximum�Likelihood�Estimation

• 목표: 주사위의확률분포를알고싶다.

• 임의의확률분포생성,�Again!

0.1 0.1 0.1 0.1 0.1

0.5

0

0.2

0.4

0.6

1 2 3 4 5 6

𝜃3 𝜃5

ℒ 𝜃# = &!"#&"%'𝑃(" x=𝑥! =.1)×.1)×.1#×.1)×.1*×.5*= 3.125𝑒 − 17
ℒ 𝜃) = &!"#&"%'𝑃(# x=𝑥! =.15)×.15)×.05#×.15)×.25*×.25*= 1.833𝑒 − 15

0.15 0.15 0.05 0.15

0.25 0.25

0

0.2

0.4

0.6

1 2 3 4 5 6



Log�Likelihood

• 앞선예제에서볼수있듯이, Likelihood는 확률값의곱으로표현됨
• Underflow의 가능성

• 따라서 Log를 취하여곱셈을덧셈으로바꾸고, Log�Likelihood로 문제를해결
• 덧셈이곱셈보다연산도빠름

2:;3< 𝑃9 x=𝑥: 4:;3< log 𝑃9 x=𝑥:



MLE�via�Gradient�Ascent

• 랜덤생성대신, Gradient�Ascent를 통해,
likelihood�값을최대로만드는파라미터(𝜃)를 찾자.

𝜃 ← 𝜃 + 𝛼 ; 𝜕ℒ 𝜃𝜕𝜃



Example�of�MLE�via�Gradient�Ascent

• 𝑛 = 100번던졌을때, 𝑘 = 27번앞면(True)이 나오는동전이있다.
이 동전의확률분포(파라미터 𝜃)를 추정하자.

• Binomial�Distributionℒ 𝜃 = 𝑛!𝑘! 𝑛 − 𝑘 !×𝜃=× 1 − 𝜃 <>=



Summary

• 우리는가상의확률분포를모사하는확률분포의파라미터(𝜃)를 찾고싶다.
• 목표확률분포로부터데이터를수집한후, 데이터를잘설명하는파라미터를찾자.

• Likelihood�라는값을통해얼마나잘설명하는지알수있다.
• Likelihood function은 𝜃를입력으로받아, 데이터들의 𝜃에대한확률값의곱을출력

• Likelihood를 최대화하는파라미터를찾으면, 주어진데이터를가장잘설명한다.
• Gradient�Ascent를 통해서찾자.


