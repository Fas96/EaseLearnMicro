
Wrap-up
Ki Hyun Kim

nlp.with.deep.learning@gmail.com




Convolutionalï¿½Neuralï¿½Networks

Beforeï¿½Deepï¿½Learning

â€¢ Convolutionï¿½filterë¥¼ í™œìš©í•˜ì—¬
hand-craftedï¿½featureï¿½ì¶”ì¶œ

Inï¿½Deepï¿½Learning

â€¢ ğ‘¥ â†’ ğ‘¦ì˜ê´€ê³„ì˜í•™ìŠµì—ì„œí•„ìš”í•œ
featureë¥¼ ì¶”ì¶œí•˜ê¸°ìœ„í•œ
convolutionï¿½filterë¥¼ ìë™í•™ìŠµ



vsï¿½Fully-connectedï¿½Layer

â€¢ ë§¤ìš°ë¹ ë¥´ê³ ì ì€ weightï¿½parameterë¥¼ ê°€ì§

â€¢ ì…ì¶œë ¥í¬ê¸°ê°€ê³„ì‚°ì´ê¹Œë‹¤ë¡œì›Œ, ë„¤íŠ¸ì›Œí¬êµ¬ì„±ì´ì‰½ì§€ì•Šë‹¤.
â€¢ 3Ã—3ì»¤ë„ì„í™œìš©í•˜ë©´ê·¸ë˜ë„ì¢€ë‚«ë‹¤.

kernel
output

input

pad

input + pad



Howï¿½toï¿½designï¿½CNNï¿½Architecture

â€¢ CNNï¿½Block
1) 3x3ï¿½Convolutionï¿½Layer

2) ReLU
3) Batchï¿½Normalization

4) 3x3ï¿½Convolutionï¿½Layerï¿½(+ï¿½withï¿½Strideï¿½sizeï¿½(2x2))
5) ReLU
6) Batchï¿½Normalization
7) (+ï¿½Max-poolingï¿½ifï¿½noï¿½stride)

CNNï¿½Block

CNNï¿½Block CNNï¿½Block CNNï¿½Block

(ğ‘ = 1, ğ¶, ğ»,ğ‘Š) (64, ğ»2 ,ğ‘Š2 ) (128, ğ»4 ,ğ‘Š4 ) (256, 1,1) (1, â„) (1, |ğ¶|)

so
ftm

ax

F
C
ï¿½Laye

r

F
C
ï¿½Laye

r



Wrap-up

â€¢ Computerï¿½visionï¿½ë¶„ì•¼ì—ì„œ CNNì„ë—„ìˆ˜ì—†ëŠ”ì¡´ì¬

â€¢ íŒ¨í„´ì¸ì‹ì—ì„œì›Œë‚™ì›”ë“±í•¨ì„ë³´ì—¬ì£¼ë¯€ë¡œ, NLP ë“±ì˜ë‹¤ë¥¸ë¶„ì•¼ì—ë„í™œë°œíˆì‚¬ìš©ë¨

[Kim,ï¿½2014]


