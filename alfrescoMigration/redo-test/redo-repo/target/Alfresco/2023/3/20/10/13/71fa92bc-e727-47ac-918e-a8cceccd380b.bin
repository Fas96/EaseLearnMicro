
PyTorch Custom�
DataSets

Ki Hyun Kim

nlp.with.deep.learning@gmail.com




What�we�need�to�do

1)Read�tabular�dataset�(e.g.�csv�file).

2)Shuffling�before�split�into�train/valid/test�set.

3)Split�train,�valid�and�test�set.

1.�Read�&�Split

1)Remove�unnecessary�rows�(e.g.�high�null�ratio).

2)Standard�or�Min/Max�Scaling�based�on�training�set.
2.�Preprocessing

1)Shuffle�for�each�epoch.

2)Get�tensor�chunk�with�mini-batch�size.

3)Yield�the�mini-batch�for�each�iteration.

3.�Iterator



We�need�well-designed�modules

1)Read�tabular�dataset�(e.g.�csv�file).

2)Shuffling�before�split�into�train/valid/test�set.

3)Split�train,�valid�and�test�set.

1.�Read�&�Split

1)Remove�unnecessary�rows�(e.g.�high�null�ratio).

2)Standard�or�Min/Max�Scaling�based�on�training�set.
2.�Preprocessing

1)Shuffle�for�each�epoch.

2)Get�tensor�chunk�with�mini-batch�size.

3)Yield�the�mini-batch�for�each�iteration.

3.�Iterator

DataSet

DataLoader



Plug�&�Play

torch.utils.data.DataSet

__getitem__(self,�idx)

__len__(self)

__init__(self,�*args,�**kwargs)

torch.utils.data.DataLoader



Plug�&�Play

torch.utils.data.DataSet

__getitem__(self,�idx)

__len__(self)

__init__(self,�*args,�**kwargs)

torch.utils.data.DataLoader

데이터를읽어오기

데이터의크기알기

전처리및
미니배치를위한샘플반환

셔플링, 미니배치구성, Yield


