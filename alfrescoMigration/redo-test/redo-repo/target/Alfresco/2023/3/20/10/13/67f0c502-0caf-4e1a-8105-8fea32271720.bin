
One-hot�Encoding
Ki Hyun Kim

nlp.with.deep.learning@gmail.com




Categorical�vs�Continuous�Value

• Categorical�Value
• 보통은 discrete�value
• 단어, 클래스

• Continuous�Value
• 키, 몸무게

• 가장결정적인차이점
• Continuous value는 비슷한값은비슷한의미를지니지만,
• Categorical�value는 비슷한값일지라도상관없는의미를지닌다.



Categorical�Value:�Text

• 단어를사전순으로 index에 mapping 해보자

• As�we�know,
• distance(연필,�볼펜) < distance(연필, 자)
• distance(공책, 필기장) < distance(공책, 딱풀)

• However,�in�the�table,
• |연필 ­ 볼펜| = 4 > 1 = |연필 ­ 자|
• |공책 ­ 필기장| = 13 > 3 = |공책 ­ 딱풀|

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15

가
위

공
책

교
과
서

노
트

딱
풀

볼
펜

색
연
필

샤
프

싸
인
펜

연
필

자 지
우
개

책
상

칼 필
기
장

필
통



One-hot�Encoding

• 크기가의미를갖는 integer 값 대신,
1개의 1과 𝑛 − 1개의 0으로이루어진 n차원의벡터

idx
가
위

공
책

교
과
서

노
트

딱
풀

볼
펜

색
연
필

샤
프

싸
인
펜

연
필

자 지
우
개

책
상

칼 필
기
장

필
통

공책 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0

노트 3 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0

지우개 11 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0

n개의항목à n차원



Sparse�vs�Dense�Vector

• Vector의 대부분의 element가 0인경우 Sparse�Vector라고부름
• 반대개념: Dense�Vector

• One-hot�vector는 Sparse�Vector의 정점(?).

공책 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0

노트 3 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0

지우개 11 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0



Problems�in�One-hot�Representation

• 서로다른두벡터는항상직교(orthogonal)한다.
• Cosine�similarity가 0.

• 따라서우리는두샘플사이의유사도(거리)를 구할수없다.

공책 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0

노트 3 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0

지우개 11 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0



Motivation�of�Embedding�Vectors

• NLP에서단어는 categorical�and�discrete�value의 속성을가짐
• 따라서 one-hot�representation으로표현
• 하지만이는실제존재하는단어사이의유사도를표현할수없음

• Word�Embedding�Vectors
• Word2Vec�또는 DNN을통해차원축소및 dense�vector로 표현



Summary

• Categorical�Value는 One-hot�Encoding을 통해벡터로표현됨

• Sparse�Vector는 벡터간유사도계산이어려움

• 따라서 Dense�Vector로 표현할필요가있음


