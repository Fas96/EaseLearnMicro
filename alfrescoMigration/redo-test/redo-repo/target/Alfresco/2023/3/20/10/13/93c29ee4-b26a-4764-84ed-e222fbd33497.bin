
Popularï¿½Backbone:
ResNet

Ki Hyun Kim

nlp.with.deep.learning@gmail.com




Introduction

â€¢ [Heï¿½etï¿½al.,ï¿½2015]ï¿½Deepï¿½Residualï¿½Learningï¿½forï¿½Imageï¿½Recognition
â€¢ [Heï¿½etï¿½al.,ï¿½2016] Identityï¿½Mappingsï¿½inï¿½Deepï¿½Residualï¿½Networks

Revolutionï¿½ofï¿½Depth
ì¶œì²˜: http://kaiminghe.com/icml16tutorial/index.html




Motivations

â€¢ ImageNetï¿½ëŒ€íšŒê°€ê±°ë“­ë ìˆ˜ë¡, ê¹Šì€ë„¤íŠ¸ì›Œí¬ê°€ìš°ìŠ¹ì„ì°¨ì§€í•¨

â€¢ ê¹Šì€ë„¤íŠ¸ì›Œí¬ë¥¼í•™ìŠµì‹œí‚¤ëŠ”ë°ì• ë¡œì‚¬í•­ì´ë§ìŒ
â€¢ ìµœì í™”ë¬¸ì œ: Trainingï¿½lossê°€ ì˜ë‚®ì•„ì§€ì§€ì•ŠìŒ

â€¢ ìµœì ì˜ê¹Šì´ê°€ì¡´ì¬í• í…ë°, ê¹Šì–´ì§€ë©´ë‚˜ë¨¸ì§€ëŠ” identityï¿½í•¨ìˆ˜ë©´ë ê²ƒì•„ë‹Œê°€?

ì¶œì²˜: http://kaiminghe.com/icml16tutorial/index.html




Methodology

â€¢ ğ¹ ğ‘¥ = ğ» ğ‘¥ âˆ’ ğ‘¥
â€¢ ğ» ğ‘¥ = ğ¹(ğ‘¥) + ğ‘¥

ğ¹ ğ‘¥

ğ» ğ‘¥



Methodology

â€¢ Residualï¿½Blockì„ ìŒ“ì



Evaluation

â€¢ ê¸°ì¡´:
â€¢ ë ˆì´ì–´ê°€ê¹Šì–´ì§ˆìˆ˜ë¡ë‚®ì€ì„±ëŠ¥

â€¢ Resnet:
â€¢ ë ˆì´ì–´ê°€ê¹Šì–´ì§ˆìˆ˜ë¡ë†’ì€ì„±ëŠ¥

Trainingï¿½errorï¿½(dashedï¿½lines)ï¿½&ï¿½Testï¿½errorï¿½(boldï¿½lines)ï¿½onï¿½CIFAR-10



Later,ï¿½itï¿½turnsï¿½out

â€¢ Resnetì€ gradientï¿½vanishingì„ ë°©ì§€í•˜ëŠ”ë°©ë²•

â€¢ ë‹¤ë¥¸ gradientï¿½vanishingï¿½ë°©ì§€ë°©ë²•
â€¢ Highwayï¿½Networksï¿½[Srivastavaï¿½etï¿½al.,ï¿½2015]
â€¢ Linearï¿½Gatedï¿½Unitï¿½[Dauphinï¿½etï¿½al.,ï¿½2016]

â€¢ í˜„ì¬ì œì•ˆë˜ëŠ”ëŒ€ë¶€ë¶„ì˜í°ë„¤íŠ¸ì›Œí¬ë“¤ì€ residualï¿½connectionì„ ì°¨ìš©
â€¢ e.g.ï¿½Transformer


